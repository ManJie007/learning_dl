"""
注意力提示

    注意力是稀缺的，而环境中的干扰注意力的信息却并不少。 
        比如人类的视觉神经系统大约每秒收到 10^8 位的信息， 这远远超过了大脑能够完全处理的水平。 
        幸运的是，人类的祖先已经从经验（也称为数据）中认识到 “并非感官的所有输入都是一样的”。 
        在整个人类历史中，这种只将注意力引向感兴趣的一小部分信息的能力， 使人类的大脑能够更明智地分配资源来生存、成长和社交， 例如发现天敌、找寻食物和伴侣

生物学中的注意力提示

    注意力是如何应用于视觉世界中的呢？这要从当今十分普及的双组件（two-component）的框架开始讲起： 
        这个框架的出现可以追溯到19世纪90年代的威廉·詹姆斯， 他被认为是“美国心理学之父” 。 
        在这个框架中，受试者基于非自主性提示和自主性提示 有选择地引导注意力的焦点。
            非自主性提示是基于环境中物体的突出性和易见性。 
                想象一下，假如我们面前有五个物品： 一份报纸、一篇研究论文、一杯咖啡、一本笔记本和一本书。 
                所有纸制品都是黑白印刷的，但咖啡杯是红色的。 
            换句话说，这个咖啡杯在这种视觉环境中是突出和显眼的， 不由自主地引起人们的注意。 
                所以我们会把视力最敏锐的地方放到咖啡上。喝咖啡后，我们会变得兴奋并想读书， 所以转过头，重新聚焦眼睛，然后看看书。 
                与上面选择咖啡杯由于突出性导致的选择不同， 此时选择书是受到了认知和意识的控制，因此注意力在基于自主性提示去辅助选择时将更为谨慎。 
            受试者的主观意愿推动，选择的力量也就更强大。

查询、键和值
    
    自主性的与非自主性的注意力提示解释了人类的注意力的方式，下面来看看如何通过这两种注意力提示，用神经网络来设计注意力机制的框架，
        首先，考虑一个相对简单的状况， 即只使用非自主性提示。 
            要想将选择偏向于感官输入， 则可以简单地使用参数化的全连接层，甚至是非参数化的最大汇聚层或平均汇聚层。

        因此，“是否包含自主性提示”将注意力机制与全连接层或汇聚层区别开来。 

        在注意力机制的背景下，自主性提示被称为查询（query）。 
            给定任何查询，注意力机制通过注意力汇聚（attention pooling） 将选择引导至感官输入（sensory inputs，例如中间特征表示）。 
            在注意力机制中，这些感官输入被称为值（value）。 
            更通俗的解释，每个值都与一个键（key）配对， 这可以想象为感官输入的非自主提示。 
            
                        注意力汇聚                      输出
        键(非意志线索)  ---------    值(感觉输入)       -----
            -----       |       |       -----           |   |
            |   |   ->  |       |       |   |           -----
            -----       |       |       -----             |
            -----       |       |       -----             |
            |   |   ->  |       |       |   |             |
            -----       |       |       -----             |
            -----       |       |       -----             |
            |   |   ->  |       |\      |   |             |
            -----       |       | \     -----             |
            -----       |       |  \    -----             |
            |   |   ->  |       |   \   |   |             |
            -----       |       |    \  -----             |
            -----       |       |     \ -----             |
            |   |   ->  |       |       |   | ------------|
            -----       |       |       -----
                        ---------
                           ^
            -----          |
            |   |   --------
            -----
        查询(意志线索)

            如上所示，可以通过设计注意力汇聚的方式， 便于给定的查询（自主性提示）与键（非自主性提示）进行匹配， 这将引导得出最匹配的值（感官输入）。

            鉴于上面所提框架的主导地位， 因此这个框架下的模型将成为本章的中心。 

        然而，注意力机制的设计有许多替代方案。 
            例如可以设计一个不可微的注意力模型， 该模型可以使用强化学习方法进行训练。

注意力的可视化

    平均汇聚层可以被视为输入的加权平均值， 其中各输入的权重是一样的。 
    实际上，注意力汇聚得到的是加权平均的总和值， 其中权重是在给定的查询和不同的键之间计算得出的。
"""
import torch
from d2l import torch as d2l

#@save
def show_heatmaps(matrices, xlabel, ylabel, titles=None, figsize=(2.5, 2.5), cmap='Reds'):
    """
    为了可视化注意力权重，需要定义一个show_heatmaps函数。 
        其输入matrices的形状是 （要显示的行数，要显示的列数，查询的数目，键的数目）。
    """
    """显示矩阵热图"""
    d2l.use_svg_display()
    num_rows, num_cols = matrices.shape[0], matrices.shape[1]
    fig, axes = d2l.plt.subplots(num_rows, num_cols, figsize=figsize,
                                 sharex=True, sharey=True, squeeze=False)
    for i, (row_axes, row_matrices) in enumerate(zip(axes, matrices)):
        for j, (ax, matrix) in enumerate(zip(row_axes, row_matrices)):
            pcm = ax.imshow(matrix.detach().numpy(), cmap=cmap)
            if i == num_rows - 1:
                ax.set_xlabel(xlabel)
            if j == 0:
                ax.set_ylabel(ylabel)
            if titles:
                ax.set_title(titles[j])
    fig.colorbar(pcm, ax=axes, shrink=0.6)

#下面使用一个简单的例子进行演示。 在本例子中，仅当查询和键相同时，注意力权重为1，否则为0。

attention_weights = torch.eye(10).reshape((1, 1, 10, 10))
show_heatmaps(attention_weights, xlabel='Keys', ylabel='Queries')

"""
后面的章节内容将经常调用show_heatmaps函数来显示注意力权重。

小结
    人类的注意力是有限的、有价值和稀缺的资源。
    受试者使用非自主性和自主性提示有选择性地引导注意力。前者基于突出性，后者则依赖于意识。
    注意力机制与全连接层或者汇聚层的区别源于增加的自主提示。
    由于包含了自主性提示，注意力机制与全连接的层或汇聚层不同。
    注意力机制通过注意力汇聚使选择偏向于值（感官输入），其中包含查询（自主性提示）和键（非自主性提示）。键和值是成对的。
    可视化查询和键之间的注意力权重是可行的。
"""
